{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'fusion_twas' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "#clone fusion_twas library before running this\n",
    "!git clone https://github.com/gusevlab/fusion_twas.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shell_do(command, log=False, return_log=False):\n",
    "    print(f'Executing: {(\" \").join(command.split())}', file=sys.stderr)\n",
    "\n",
    "    res=subprocess.run(command.split(), stdout=subprocess.PIPE)\n",
    "\n",
    "    if log:\n",
    "        print(res.stdout.decode('utf-8'))\n",
    "    if return_log:\n",
    "        return(res.stdout.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set paths\n",
    "basedir = '/data/songy4/tes'\n",
    "datadir = f'{basedir}/data_folder'\n",
    "fusiondir = f'/data/songy4/twas/fusion_twas'\n",
    "geno_path_case = f'{datadir}/qc_genotypes_tes_case_hg19_lifted'\n",
    "geno_path_cont = f'{datadir}/qc_genotypes_tes_control_hg19_lifted'\n",
    "transcript_list_path = f'{datadir}/transcript_list.txt'\n",
    "te_list_path = f'{datadir}/te_list.txt'\n",
    "pheno_path_tecase = f'{datadir}/baseline_te_case.txt'\n",
    "pheno_path_tecont = f'{datadir}/baseline_te_control.txt'\n",
    "pheno_path_trcase = f'{datadir}/base_transcript_case.txt'\n",
    "pheno_path_trcont = f'{datadir}/base_transcript_control.txt'\n",
    "coord_path_te = f'{datadir}/te_coordinate.txt'\n",
    "coord_path_tr = f'{datadir}/transcript_coordinate.txt'\n",
    "covar_path_case = f'{datadir}/te_covariates_case.txt'\n",
    "covar_path_cont = f'{datadir}/te_covariates_control.txt'\n",
    "gcta = f'{fusiondir}/gcta_nr_robust'\n",
    "gemma = f'gemma-0.98.3-linux-static'\n",
    "fusion_ldref_basename = f'{fusiondir}/LDREF/1000G.EUR'\n",
    "fusion_compute_weights_script = f'{fusiondir}/FUSION.compute_weights.R'\n",
    "\n",
    "!mkdir --parents {basedir}/output/weights_case\n",
    "!mkdir --parents {basedir}/output/tmp_case\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline for TWAS run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get gene list\n",
    "##test with couple genes first before running all gene_list\n",
    "#transcript_list_df = pd.read_csv(transcript_list_path, engine='c',sep='\\t')\n",
    "#transcript_list = list(transcript_list_df.ID)\n",
    "#transcript_list = ['ENST00000000233.10', 'ENST00000000412.8', 'ENST00000000442.11'] # for testing\n",
    "# gene_list = ['ENSG00000186092']\n",
    "#pheno_trcase = pd.read_csv(pheno_path_trcase, engine='c', sep='\\t')\n",
    "#pheno_trcont = pd.read_csv(pheno_path_trcont, engine='c',sep='\\t')\n",
    "#coords = pd.read_csv(coord_path_tr, engine='c',sep='\\t')\n",
    "#covars_case = pd.read_csv(covar_path_case, engine='c',sep='\\t')\n",
    "#covars_cont = pd.read_csv(covar_path_cont, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now put together pipeline\n",
    "covars = pd.read_csv(covar_path_case, sep='\\t')\n",
    "\n",
    "for i in range(21 ,23): \n",
    "    pheno_i = pd.read_csv(f'{datadir}/base_transcript_case_chr{i}.txt', engine='c')\n",
    "    coords_i = pd.read_csv(f'{datadir}/transcript_coordinate_chr{i}.txt',  engine='c')\n",
    "    gene_list_df_i = pd.read_csv(f'{datadir}/transcript_list_chr{i}.txt', engine='c')\n",
    "    gene_list_i = list(gene_list_df_i.ID)\n",
    "    \n",
    "    compweights_swarmfile_i = f'{basedir}/compute_weights_{i}.swarm'\n",
    "\n",
    "    with open(compweights_swarmfile_i, 'w') as f:\n",
    "    \n",
    "        for gene in gene_list_i:\n",
    "            OUT = f'output/tmp_case/{gene}'\n",
    "            FINAL_OUT = f'output/weights_case/{gene}'\n",
    "            #get chr start stop\n",
    "            _chr = coords_i.loc[coords_i.ID == gene, 'X.Chr'].item()\n",
    "            _start = coords_i.loc[coords_i.ID == gene, 'start'].item()-0.5e6\n",
    "            _stop = coords_i.loc[coords_i.ID == gene, 'end'].item()+0.5e6\n",
    "\n",
    "            if _start < 0:\n",
    "                _start = 0\n",
    "\n",
    "            _start = int(_start)\n",
    "            _stop = int(_stop)\n",
    "\n",
    "            pheno_i[['FID','IID', gene]].to_csv(f'{OUT}.pheno', sep='\\t', header=False, index=False)\n",
    "    #         pheno[['FID','IID', gene]].to_csv(_phenoname, sep='\\t', header=False, index=False)\n",
    "\n",
    "            plink_cmd_i = f'\\\n",
    "plink --bfile {geno_path_case} \\\n",
    "--pheno {OUT}.pheno \\\n",
    "--keep {OUT}.pheno \\\n",
    "--chr {_chr} \\\n",
    "--from-bp {_start} \\\n",
    "--to-bp {_stop} \\\n",
    "--extract {fusion_ldref_basename}.{_chr}.bim \\\n",
    "--make-bed \\\n",
    "--out {OUT}'  \n",
    "\n",
    "#        shell_do(plink_cmd, log=True, return_log=True)\n",
    "\n",
    "            fusion_cmd_i = f'\\\n",
    "Rscript {fusion_compute_weights_script} \\\n",
    "--bfile {OUT} \\\n",
    "--tmp {OUT}.tmp \\\n",
    "--out {FINAL_OUT} \\\n",
    "--PATH_gemma {gemma} \\\n",
    "--PATH_plink plink \\\n",
    "--PATH_gcta {gcta} \\\n",
    "--covar {covar_path_case} \\\n",
    "--verbose 2 \\\n",
    "--save_hsq \\\n",
    "--models top1,lasso,enet'\n",
    "##include \"blup,bslmm\" to the --models in fusion_cmd for future     \n",
    "# \n",
    "#        shell_do(fusion_cmd, log=True, return_log=True)\n",
    "\n",
    "            f.write(f'{plink_cmd_i} && {fusion_cmd_i}\\n')\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "swarm -f /data/songy4/tes/compute_weights_3.swarm -g 16 -t 16 --time=10:00:00 --logdir swarm --gres=lscratch:20 --module plink,GEMMA/0.96 --partition=norm\n",
      "15461033\n"
     ]
    }
   ],
   "source": [
    "# run swarm\n",
    "#compweights_swarmfile_3 = f'{basedir}/compute_weights_3.swarm'\n",
    "#swarm_cmd_3 = f'swarm -f {compweights_swarmfile_3} -g 16 -t 16 --time=10:00:00 --logdir swarm --gres=lscratch:20 --module plink,GEMMA/0.96 --partition=norm'\n",
    "# shell_do(swarm_cmd)\n",
    "#print(swarm_cmd_3)\n",
    "#!{swarm_cmd_3}\n",
    "##check swarm jobs state in hpc.nih.gov/dashboard/\n",
    "##check .e, .o, and .log files of swarm jobs in swarm folder (same name as swarm jobid in hpc dashboard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "swarm -f /data/songy4/tes/compute_weights_21.swarm -g 16 -t 16 --time=10:00:00 --logdir swarm --gres=lscratch:20 --module plink,GEMMA/0.96 --partition=norm\n",
      "16844245\n",
      "swarm -f /data/songy4/tes/compute_weights_22.swarm -g 16 -t 16 --time=10:00:00 --logdir swarm --gres=lscratch:20 --module plink,GEMMA/0.96 --partition=norm\n",
      "16844251\n"
     ]
    }
   ],
   "source": [
    "# run swarm\n",
    "for i in range(21,23): \n",
    "    compweights_swarmfile_i = f'{basedir}/compute_weights_{i}.swarm'\n",
    "    swarm_cmd_i = f'swarm -f {compweights_swarmfile_i} -g 8 -t 2 --time=10:00:00 --logdir swarm --gres=lscratch:20 --module plink,GEMMA/0.96 --partition=norm'\n",
    "#--devel\n",
    "# shell_do(swarm_cmd)\n",
    "    print(swarm_cmd_i)\n",
    "    !{swarm_cmd_i}\n",
    "###for this specific project, 8GB memory and 2 CPU are enough###\n",
    "##check swarm jobs state in hpc.nih.gov/dashboard/\n",
    "##check .e, .o, and .log files of swarm jobs in swarm folder (same name as swarm jobid in hpc dashboard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61\n",
      "ls: cannot access ./*.RDat: No such file or directory\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#check number of weights in output/weights folder \n",
    "###run this in terminal\n",
    "\n",
    "#go to the weights folder\n",
    "!cd /data/songy4/tes/output/weights_case\n",
    "#check how many files are in total\n",
    "! ls | wc -l\n",
    "#there are 218193\n",
    "#check how many .RDat file is in weights folder\n",
    "!ls -lR ./*.RDat | wc -l\n",
    "#there are 9482 RDat files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TWAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>CHR</th>\n",
       "      <th>P0</th>\n",
       "      <th>P1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENST00000467231.5</td>\n",
       "      <td>1</td>\n",
       "      <td>90916390</td>\n",
       "      <td>91022014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENST00000359621.5</td>\n",
       "      <td>1</td>\n",
       "      <td>15456732</td>\n",
       "      <td>15472091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENST00000470394.1</td>\n",
       "      <td>1</td>\n",
       "      <td>21233570</td>\n",
       "      <td>21238350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENST00000470395.1</td>\n",
       "      <td>1</td>\n",
       "      <td>54032019</td>\n",
       "      <td>54036802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENST00000470396.1</td>\n",
       "      <td>1</td>\n",
       "      <td>151266308</td>\n",
       "      <td>151266725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219238</th>\n",
       "      <td>ENST00000447224.5</td>\n",
       "      <td>22</td>\n",
       "      <td>30555938</td>\n",
       "      <td>30560759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219239</th>\n",
       "      <td>ENST00000472551.1</td>\n",
       "      <td>22</td>\n",
       "      <td>44196098</td>\n",
       "      <td>44219533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219240</th>\n",
       "      <td>ENST00000447261.6</td>\n",
       "      <td>22</td>\n",
       "      <td>24632915</td>\n",
       "      <td>24647760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219241</th>\n",
       "      <td>ENST00000426113.5</td>\n",
       "      <td>22</td>\n",
       "      <td>20967248</td>\n",
       "      <td>20974096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219242</th>\n",
       "      <td>ENST00000463909.1</td>\n",
       "      <td>22</td>\n",
       "      <td>20995089</td>\n",
       "      <td>20999032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>219243 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       ID  CHR         P0         P1\n",
       "0       ENST00000467231.5    1   90916390   91022014\n",
       "1       ENST00000359621.5    1   15456732   15472091\n",
       "2       ENST00000470394.1    1   21233570   21238350\n",
       "3       ENST00000470395.1    1   54032019   54036802\n",
       "4       ENST00000470396.1    1  151266308  151266725\n",
       "...                   ...  ...        ...        ...\n",
       "219238  ENST00000447224.5   22   30555938   30560759\n",
       "219239  ENST00000472551.1   22   44196098   44219533\n",
       "219240  ENST00000447261.6   22   24632915   24647760\n",
       "219241  ENST00000426113.5   22   20967248   20974096\n",
       "219242  ENST00000463909.1   22   20995089   20999032\n",
       "\n",
       "[219243 rows x 4 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#open gene_chr_start_stop.tab -- this has chr and position info\n",
    "chr_pos_df = pd.read_csv(coord_path_tr, sep='\\t')\n",
    "#rearrange the columns \n",
    "chr_pos_df = chr_pos_df[['ID', 'X.Chr','start','end']]\n",
    "#change column names in chr_pos_df\n",
    "chr_pos_df.columns = ['ID', 'CHR', 'P0', 'P1']\n",
    "\n",
    "chr_pos_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make gene_path.csv\n",
    "! ls -l ./output/weights_case | grep -E 'ENSG|.RDat' | awk '{print $9\", ./weights/\"$9}' | sed 's/.wgt.RDat,/,/g' > ./data_folder/gene_path_case.csv\n",
    "\n",
    "## list files in weights folder, search lines with same pattern as 'ENSG'\n",
    "## scan file line by line, splits each input line\n",
    "## substitute .wgt.RDat, with , in all occurrences (/g means global replacement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                       ID                                     WGT\n",
       "0      ENST00000001146.6    ./weights/ENST00000001146.6.wgt.RDat\n",
       "1      ENST00000004103.8    ./weights/ENST00000004103.8.wgt.RDat\n",
       "2     ENST00000008180.13   ./weights/ENST00000008180.13.wgt.RDat\n",
       "3     ENST00000009041.11   ./weights/ENST00000009041.11.wgt.RDat\n",
       "4     ENST00000011989.11   ./weights/ENST00000011989.11.wgt.RDat\n",
       "...                  ...                                     ...\n",
       "9477   ENST00000673312.1    ./weights/ENST00000673312.1.wgt.RDat\n",
       "9478   ENST00000673427.1    ./weights/ENST00000673427.1.wgt.RDat\n",
       "9479   ENST00000673452.1    ./weights/ENST00000673452.1.wgt.RDat\n",
       "9480   ENST00000673471.1    ./weights/ENST00000673471.1.wgt.RDat\n",
       "9481   ENST00000673487.1    ./weights/ENST00000673487.1.wgt.RDat\n",
       "\n",
       "[9482 rows x 2 columns]>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import gene_path.csv \n",
    "path = pd.read_csv(f\"{datadir}/gene_path_case.csv\", names=['ID', 'WGT'])\n",
    "path.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                        ID                                     WGT\n",
       "0       ENST00000001146.6    ./weights/ENST00000001146.6.wgt.RDat\n",
       "1       ENST00000004103.8    ./weights/ENST00000004103.8.wgt.RDat\n",
       "2      ENST00000008180.13   ./weights/ENST00000008180.13.wgt.RDat\n",
       "3      ENST00000009041.11   ./weights/ENST00000009041.11.wgt.RDat\n",
       "4      ENST00000011989.11   ./weights/ENST00000011989.11.wgt.RDat\n",
       "...                   ...                                     ...\n",
       "11576   ENST00000673312.1    ./weights/ENST00000673312.1.wgt.RDat\n",
       "11577   ENST00000673427.1    ./weights/ENST00000673427.1.wgt.RDat\n",
       "11578   ENST00000673452.1    ./weights/ENST00000673452.1.wgt.RDat\n",
       "11579   ENST00000673471.1    ./weights/ENST00000673471.1.wgt.RDat\n",
       "11580   ENST00000673487.1    ./weights/ENST00000673487.1.wgt.RDat\n",
       "\n",
       "[11581 rows x 2 columns]>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove .hsq rows --> didn't need in this\n",
    "#path = path[~path.WGT.str.contains(\".hsq\")]\n",
    "#path.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save path as csv -- run only once for download\n",
    "#path.to_csv(r'./data_folder/gene_path_case.csv' ,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                      ID  CHR         P0         P1  \\\n",
       "0     ENST00000629041.1    1   45581219   45581321   \n",
       "1     ENST00000470459.6    1  161222296  161223628   \n",
       "2     ENST00000470472.5    1   35176378   35190574   \n",
       "3     ENST00000417869.6    1   39522287   39556662   \n",
       "4     ENST00000647711.1    1  109711780  109715240   \n",
       "...                 ...  ...        ...        ...   \n",
       "9477  ENST00000426108.1   22   36178554   36179385   \n",
       "9478  ENST00000609499.5   22   42118347   42124899   \n",
       "9479  ENST00000472589.1   22   42554909   42555966   \n",
       "9480  ENST00000472575.5   22   20965177   20973619   \n",
       "9481  ENST00000426113.5   22   20967248   20974096   \n",
       "\n",
       "                                        WGT  \n",
       "0      ./weights/ENST00000629041.1.wgt.RDat  \n",
       "1      ./weights/ENST00000470459.6.wgt.RDat  \n",
       "2      ./weights/ENST00000470472.5.wgt.RDat  \n",
       "3      ./weights/ENST00000417869.6.wgt.RDat  \n",
       "4      ./weights/ENST00000647711.1.wgt.RDat  \n",
       "...                                     ...  \n",
       "9477   ./weights/ENST00000426108.1.wgt.RDat  \n",
       "9478   ./weights/ENST00000609499.5.wgt.RDat  \n",
       "9479   ./weights/ENST00000472589.1.wgt.RDat  \n",
       "9480   ./weights/ENST00000472575.5.wgt.RDat  \n",
       "9481   ./weights/ENST00000426113.5.wgt.RDat  \n",
       "\n",
       "[9482 rows x 5 columns]>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#merge chr_pos_df and path\n",
    "merged = chr_pos_df.merge(path, how='inner', on='ID')\n",
    "merged.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check chr \n",
    "chr_list = merged['CHR'].unique().tolist()\n",
    "chr_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Anaconda/envs/py3.7/lib/python3.7/site-packages/ipykernel_launcher.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                      ID  CHR         P0         P1  \\\n",
       "0     ENST00000629041.1    1   45581219   45581321   \n",
       "1     ENST00000470459.6    1  161222296  161223628   \n",
       "2     ENST00000470472.5    1   35176378   35190574   \n",
       "3     ENST00000417869.6    1   39522287   39556662   \n",
       "4     ENST00000647711.1    1  109711780  109715240   \n",
       "...                 ...  ...        ...        ...   \n",
       "9477  ENST00000426108.1   22   36178554   36179385   \n",
       "9478  ENST00000609499.5   22   42118347   42124899   \n",
       "9479  ENST00000472589.1   22   42554909   42555966   \n",
       "9480  ENST00000472575.5   22   20965177   20973619   \n",
       "9481  ENST00000426113.5   22   20967248   20974096   \n",
       "\n",
       "                              WGT  \n",
       "0      ENST00000629041.1.wgt.RDat  \n",
       "1      ENST00000470459.6.wgt.RDat  \n",
       "2      ENST00000470472.5.wgt.RDat  \n",
       "3      ENST00000417869.6.wgt.RDat  \n",
       "4      ENST00000647711.1.wgt.RDat  \n",
       "...                           ...  \n",
       "9477   ENST00000426108.1.wgt.RDat  \n",
       "9478   ENST00000609499.5.wgt.RDat  \n",
       "9479   ENST00000472589.1.wgt.RDat  \n",
       "9480   ENST00000472575.5.wgt.RDat  \n",
       "9481   ENST00000426113.5.wgt.RDat  \n",
       "\n",
       "[9482 rows x 5 columns]>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop ./weights/ from WGT\n",
    "merged['WGT'] = merged['WGT'].str.replace('./weights/', '')\n",
    "merged.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rearrange columns and save the file as synapse.pos\n",
    "output = merged[['WGT', 'ID', 'CHR', 'P1', 'P0']]\n",
    "output.to_csv(r'./data_folder/synapse_case.pos', index=False, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the RDat file sizes - check few files from above in terminal: the file sizes are ranging 500-1200\n",
    "#ls -l filename   #Displays Size of the specified file\n",
    "#ls -l *          #Displays Size of All the files in the current directory\n",
    "#ls -al *         #Displays Size of All the files including hidden files in the current directory\n",
    "#ls -al dir/      #Displays Size of All the files including hidden files in the 'dir' directory\n",
    "\n",
    "!ls -l ENST00000426108.1.wgt.RDat "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set paths\n",
    "sumstat_path = f'{datadir}/meta.txt'\n",
    "weights_path = f'{datadir}/synapse_case.pos'\n",
    "weights_dir = f'{basedir}/output/weights_case/'\n",
    "fusiondir = f'/data/songy4/twas/fusion_twas'\n",
    "fusion_ldref_basename = f'{fusiondir}/LDREF/1000G.EUR'\n",
    "fusion_assoc_script = f'{fusiondir}/FUSION.assoc_test.R'\n",
    "\n",
    "!mkdir --parents output/pd_case\n",
    "\n",
    "sumstat = pd.read_csv(sumstat_path, sep='\\t')\n",
    "\n",
    "##check if weights_dir should be f'{basedir}/output/weights'####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Executing: Rscript /data/songy4/twas/fusion_twas/FUSION.assoc_test.R --sumstats /data/songy4/tes/data_folder/meta.txt --weights /data/songy4/tes/data_folder/synapse_case.pos --weights_dir /data/songy4/tes/output/weights_case/ --ref_ld_chr /data/songy4/twas/fusion_twas/LDREF/1000G.EUR. --chr 1 --out output/pd_case/PD_case.1.dat\n",
      "Executing: Rscript /data/songy4/twas/fusion_twas/FUSION.assoc_test.R --sumstats /data/songy4/tes/data_folder/meta.txt --weights /data/songy4/tes/data_folder/synapse_case.pos --weights_dir /data/songy4/tes/output/weights_case/ --ref_ld_chr /data/songy4/twas/fusion_twas/LDREF/1000G.EUR. --chr 2 --out output/pd_case/PD_case.2.dat\n",
      "Executing: Rscript /data/songy4/twas/fusion_twas/FUSION.assoc_test.R --sumstats /data/songy4/tes/data_folder/meta.txt --weights /data/songy4/tes/data_folder/synapse_case.pos --weights_dir /data/songy4/tes/output/weights_case/ --ref_ld_chr /data/songy4/twas/fusion_twas/LDREF/1000G.EUR. --chr 3 --out output/pd_case/PD_case.3.dat\n",
      "Executing: Rscript /data/songy4/twas/fusion_twas/FUSION.assoc_test.R --sumstats /data/songy4/tes/data_folder/meta.txt --weights /data/songy4/tes/data_folder/synapse_case.pos --weights_dir /data/songy4/tes/output/weights_case/ --ref_ld_chr /data/songy4/twas/fusion_twas/LDREF/1000G.EUR. --chr 4 --out output/pd_case/PD_case.4.dat\n",
      "Executing: Rscript /data/songy4/twas/fusion_twas/FUSION.assoc_test.R --sumstats /data/songy4/tes/data_folder/meta.txt --weights /data/songy4/tes/data_folder/synapse_case.pos --weights_dir /data/songy4/tes/output/weights_case/ --ref_ld_chr /data/songy4/twas/fusion_twas/LDREF/1000G.EUR. --chr 5 --out output/pd_case/PD_case.5.dat\n",
      "Executing: Rscript /data/songy4/twas/fusion_twas/FUSION.assoc_test.R --sumstats /data/songy4/tes/data_folder/meta.txt --weights /data/songy4/tes/data_folder/synapse_case.pos --weights_dir /data/songy4/tes/output/weights_case/ --ref_ld_chr /data/songy4/twas/fusion_twas/LDREF/1000G.EUR. --chr 6 --out output/pd_case/PD_case.6.dat\n",
      "Executing: Rscript /data/songy4/twas/fusion_twas/FUSION.assoc_test.R --sumstats /data/songy4/tes/data_folder/meta.txt --weights /data/songy4/tes/data_folder/synapse_case.pos --weights_dir /data/songy4/tes/output/weights_case/ --ref_ld_chr /data/songy4/twas/fusion_twas/LDREF/1000G.EUR. --chr 7 --out output/pd_case/PD_case.7.dat\n",
      "Executing: Rscript /data/songy4/twas/fusion_twas/FUSION.assoc_test.R --sumstats /data/songy4/tes/data_folder/meta.txt --weights /data/songy4/tes/data_folder/synapse_case.pos --weights_dir /data/songy4/tes/output/weights_case/ --ref_ld_chr /data/songy4/twas/fusion_twas/LDREF/1000G.EUR. --chr 8 --out output/pd_case/PD_case.8.dat\n",
      "Executing: Rscript /data/songy4/twas/fusion_twas/FUSION.assoc_test.R --sumstats /data/songy4/tes/data_folder/meta.txt --weights /data/songy4/tes/data_folder/synapse_case.pos --weights_dir /data/songy4/tes/output/weights_case/ --ref_ld_chr /data/songy4/twas/fusion_twas/LDREF/1000G.EUR. --chr 9 --out output/pd_case/PD_case.9.dat\n",
      "Executing: Rscript /data/songy4/twas/fusion_twas/FUSION.assoc_test.R --sumstats /data/songy4/tes/data_folder/meta.txt --weights /data/songy4/tes/data_folder/synapse_case.pos --weights_dir /data/songy4/tes/output/weights_case/ --ref_ld_chr /data/songy4/twas/fusion_twas/LDREF/1000G.EUR. --chr 10 --out output/pd_case/PD_case.10.dat\n",
      "Executing: Rscript /data/songy4/twas/fusion_twas/FUSION.assoc_test.R --sumstats /data/songy4/tes/data_folder/meta.txt --weights /data/songy4/tes/data_folder/synapse_case.pos --weights_dir /data/songy4/tes/output/weights_case/ --ref_ld_chr /data/songy4/twas/fusion_twas/LDREF/1000G.EUR. --chr 11 --out output/pd_case/PD_case.11.dat\n",
      "Executing: Rscript /data/songy4/twas/fusion_twas/FUSION.assoc_test.R --sumstats /data/songy4/tes/data_folder/meta.txt --weights /data/songy4/tes/data_folder/synapse_case.pos --weights_dir /data/songy4/tes/output/weights_case/ --ref_ld_chr /data/songy4/twas/fusion_twas/LDREF/1000G.EUR. --chr 12 --out output/pd_case/PD_case.12.dat\n",
      "Executing: Rscript /data/songy4/twas/fusion_twas/FUSION.assoc_test.R --sumstats /data/songy4/tes/data_folder/meta.txt --weights /data/songy4/tes/data_folder/synapse_case.pos --weights_dir /data/songy4/tes/output/weights_case/ --ref_ld_chr /data/songy4/twas/fusion_twas/LDREF/1000G.EUR. --chr 13 --out output/pd_case/PD_case.13.dat\n",
      "Executing: Rscript /data/songy4/twas/fusion_twas/FUSION.assoc_test.R --sumstats /data/songy4/tes/data_folder/meta.txt --weights /data/songy4/tes/data_folder/synapse_case.pos --weights_dir /data/songy4/tes/output/weights_case/ --ref_ld_chr /data/songy4/twas/fusion_twas/LDREF/1000G.EUR. --chr 14 --out output/pd_case/PD_case.14.dat\n",
      "Executing: Rscript /data/songy4/twas/fusion_twas/FUSION.assoc_test.R --sumstats /data/songy4/tes/data_folder/meta.txt --weights /data/songy4/tes/data_folder/synapse_case.pos --weights_dir /data/songy4/tes/output/weights_case/ --ref_ld_chr /data/songy4/twas/fusion_twas/LDREF/1000G.EUR. --chr 15 --out output/pd_case/PD_case.15.dat\n",
      "Executing: Rscript /data/songy4/twas/fusion_twas/FUSION.assoc_test.R --sumstats /data/songy4/tes/data_folder/meta.txt --weights /data/songy4/tes/data_folder/synapse_case.pos --weights_dir /data/songy4/tes/output/weights_case/ --ref_ld_chr /data/songy4/twas/fusion_twas/LDREF/1000G.EUR. --chr 16 --out output/pd_case/PD_case.16.dat\n",
      "Executing: Rscript /data/songy4/twas/fusion_twas/FUSION.assoc_test.R --sumstats /data/songy4/tes/data_folder/meta.txt --weights /data/songy4/tes/data_folder/synapse_case.pos --weights_dir /data/songy4/tes/output/weights_case/ --ref_ld_chr /data/songy4/twas/fusion_twas/LDREF/1000G.EUR. --chr 17 --out output/pd_case/PD_case.17.dat\n",
      "Executing: Rscript /data/songy4/twas/fusion_twas/FUSION.assoc_test.R --sumstats /data/songy4/tes/data_folder/meta.txt --weights /data/songy4/tes/data_folder/synapse_case.pos --weights_dir /data/songy4/tes/output/weights_case/ --ref_ld_chr /data/songy4/twas/fusion_twas/LDREF/1000G.EUR. --chr 18 --out output/pd_case/PD_case.18.dat\n",
      "Executing: Rscript /data/songy4/twas/fusion_twas/FUSION.assoc_test.R --sumstats /data/songy4/tes/data_folder/meta.txt --weights /data/songy4/tes/data_folder/synapse_case.pos --weights_dir /data/songy4/tes/output/weights_case/ --ref_ld_chr /data/songy4/twas/fusion_twas/LDREF/1000G.EUR. --chr 19 --out output/pd_case/PD_case.19.dat\n",
      "Executing: Rscript /data/songy4/twas/fusion_twas/FUSION.assoc_test.R --sumstats /data/songy4/tes/data_folder/meta.txt --weights /data/songy4/tes/data_folder/synapse_case.pos --weights_dir /data/songy4/tes/output/weights_case/ --ref_ld_chr /data/songy4/twas/fusion_twas/LDREF/1000G.EUR. --chr 20 --out output/pd_case/PD_case.20.dat\n",
      "Executing: Rscript /data/songy4/twas/fusion_twas/FUSION.assoc_test.R --sumstats /data/songy4/tes/data_folder/meta.txt --weights /data/songy4/tes/data_folder/synapse_case.pos --weights_dir /data/songy4/tes/output/weights_case/ --ref_ld_chr /data/songy4/twas/fusion_twas/LDREF/1000G.EUR. --chr 21 --out output/pd_case/PD_case.21.dat\n",
      "Executing: Rscript /data/songy4/twas/fusion_twas/FUSION.assoc_test.R --sumstats /data/songy4/tes/data_folder/meta.txt --weights /data/songy4/tes/data_folder/synapse_case.pos --weights_dir /data/songy4/tes/output/weights_case/ --ref_ld_chr /data/songy4/twas/fusion_twas/LDREF/1000G.EUR. --chr 22 --out output/pd_case/PD_case.22.dat\n"
     ]
    }
   ],
   "source": [
    "#fusion calculation -- take about 3 min each chromosome \n",
    "for i in range(1, 23):\n",
    "    PD_OUT = f'output/pd_case/PD_case.{i}.dat'\n",
    "    fusion_cmd_i = f'\\\n",
    "    Rscript {fusion_assoc_script} \\\n",
    "    --sumstats {sumstat_path} \\\n",
    "    --weights {weights_path} \\\n",
    "    --weights_dir {weights_dir} \\\n",
    "    --ref_ld_chr {fusion_ldref_basename}. \\\n",
    "    --chr {i} \\\n",
    "    --out {PD_OUT}'\n",
    "    shell_do(fusion_cmd_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# running list of questions\n",
    "1. what about non-autosome transcripts? i.e. MT\n",
    "2. how many snps in common between ref and geno?\n",
    "3. how many snps per transcript should we expect (0-500?)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gemma -miss 1 -maf 0 -r2 1 -rpace 1000 -wpace 1000 -bfile tmp/ENSG00000188976.tmp.cv -bslmm 2 -o ENSG00000188976'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_in = 'tmp/ENSG00000188976.tmp.cv'\n",
    "f\"gemma -miss 1 -maf 0 -r2 1 -rpace 1000 -wpace 1000 -bfile {p_in} -bslmm 2 -o ENSG00000188976\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python/3.7",
   "language": "python",
   "name": "py3.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
